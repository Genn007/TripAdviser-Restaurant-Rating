{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   \n\n\n\n### И самое важное, все это вы сможете сделать самостоятельно!\n\n*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \nВы можете использовать его как основу для построения своего решения.\n\n> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \nТакже baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n\nВ контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются).","metadata":{}},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time, re\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Удобный инструмент для анализа модальности отзыва\nfrom textblob import TextBlob\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndirnames = set()\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        dirnames.add(dirname)\n        \n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-10-18T09:14:44.165977Z","iopub.execute_input":"2021-10-18T09:14:44.166333Z","iopub.status.idle":"2021-10-18T09:14:44.192585Z","shell.execute_reply.started":"2021-10-18T09:14:44.166281Z","shell.execute_reply":"2021-10-18T09:14:44.191789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 17","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:14:46.609062Z","iopub.execute_input":"2021-10-18T09:14:46.60957Z","iopub.status.idle":"2021-10-18T09:14:46.61394Z","shell.execute_reply.started":"2021-10-18T09:14:46.609512Z","shell.execute_reply":"2021-10-18T09:14:46.613002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:14:47.812992Z","iopub.execute_input":"2021-10-18T09:14:47.813336Z","iopub.status.idle":"2021-10-18T09:14:50.435408Z","shell.execute_reply.started":"2021-10-18T09:14:47.813271Z","shell.execute_reply":"2021-10-18T09:14:50.434227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-18T09:15:33.915657Z","iopub.execute_input":"2021-10-18T09:15:33.916039Z","iopub.status.idle":"2021-10-18T09:15:34.334755Z","shell.execute_reply.started":"2021-10-18T09:15:33.915983Z","shell.execute_reply":"2021-10-18T09:15:34.333625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:38.002876Z","iopub.execute_input":"2021-10-18T09:15:38.003192Z","iopub.status.idle":"2021-10-18T09:15:38.044784Z","shell.execute_reply.started":"2021-10-18T09:15:38.003146Z","shell.execute_reply":"2021-10-18T09:15:38.043789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:42.342377Z","iopub.execute_input":"2021-10-18T09:15:42.342712Z","iopub.status.idle":"2021-10-18T09:15:42.362561Z","shell.execute_reply.started":"2021-10-18T09:15:42.342665Z","shell.execute_reply":"2021-10-18T09:15:42.361759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:42.794296Z","iopub.execute_input":"2021-10-18T09:15:42.794648Z","iopub.status.idle":"2021-10-18T09:15:42.814018Z","shell.execute_reply.started":"2021-10-18T09:15:42.794587Z","shell.execute_reply":"2021-10-18T09:15:42.813115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:45.626734Z","iopub.execute_input":"2021-10-18T09:15:45.62726Z","iopub.status.idle":"2021-10-18T09:15:45.645379Z","shell.execute_reply.started":"2021-10-18T09:15:45.627185Z","shell.execute_reply":"2021-10-18T09:15:45.644301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:48.474146Z","iopub.execute_input":"2021-10-18T09:15:48.474469Z","iopub.status.idle":"2021-10-18T09:15:48.484868Z","shell.execute_reply.started":"2021-10-18T09:15:48.474407Z","shell.execute_reply":"2021-10-18T09:15:48.483979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:50.948298Z","iopub.execute_input":"2021-10-18T09:15:50.948654Z","iopub.status.idle":"2021-10-18T09:15:50.959143Z","shell.execute_reply.started":"2021-10-18T09:15:50.948604Z","shell.execute_reply":"2021-10-18T09:15:50.957908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:54.458151Z","iopub.execute_input":"2021-10-18T09:15:54.458445Z","iopub.status.idle":"2021-10-18T09:15:54.520549Z","shell.execute_reply.started":"2021-10-18T09:15:54.458396Z","shell.execute_reply":"2021-10-18T09:15:54.519536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:55.2014Z","iopub.execute_input":"2021-10-18T09:15:55.201735Z","iopub.status.idle":"2021-10-18T09:15:55.247768Z","shell.execute_reply.started":"2021-10-18T09:15:55.201684Z","shell.execute_reply":"2021-10-18T09:15:55.246594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dirnames)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:56.169568Z","iopub.execute_input":"2021-10-18T09:15:56.16997Z","iopub.status.idle":"2021-10-18T09:15:56.175034Z","shell.execute_reply.started":"2021-10-18T09:15:56.169898Z","shell.execute_reply":"2021-10-18T09:15:56.174257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cities = pd.read_csv('/kaggle/input/cities-info-for-ta-restaurant-rating/Cities.csv') \n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:15:57.043621Z","iopub.execute_input":"2021-10-18T09:15:57.043975Z","iopub.status.idle":"2021-10-18T09:15:57.057858Z","shell.execute_reply.started":"2021-10-18T09:15:57.043915Z","shell.execute_reply":"2021-10-18T09:15:57.056943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cities.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:00.328224Z","iopub.execute_input":"2021-10-18T09:16:00.328547Z","iopub.status.idle":"2021-10-18T09:16:00.339739Z","shell.execute_reply.started":"2021-10-18T09:16:00.328498Z","shell.execute_reply":"2021-10-18T09:16:00.338949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана","metadata":{}},{"cell_type":"code","source":"data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:04.68702Z","iopub.execute_input":"2021-10-18T09:16:04.687342Z","iopub.status.idle":"2021-10-18T09:16:04.710573Z","shell.execute_reply.started":"2021-10-18T09:16:04.687285Z","shell.execute_reply":"2021-10-18T09:16:04.709493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Reviews[1]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:05.79266Z","iopub.execute_input":"2021-10-18T09:16:05.792954Z","iopub.status.idle":"2021-10-18T09:16:05.800773Z","shell.execute_reply.started":"2021-10-18T09:16:05.792917Z","shell.execute_reply":"2021-10-18T09:16:05.799821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки.","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию.","metadata":{}},{"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:10.67583Z","iopub.execute_input":"2021-10-18T09:16:10.676305Z","iopub.status.idle":"2021-10-18T09:16:11.043693Z","shell.execute_reply.started":"2021-10-18T09:16:10.67626Z","shell.execute_reply":"2021-10-18T09:16:11.042885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Добавляю внешние данные из набора - отношение к стране и численность города","metadata":{}},{"cell_type":"code","source":"cities = pd.read_csv('/kaggle/input/cities-info-for-ta-restaurant-rating/Cities.csv') \njoined = data.merge(cities, on='City', how='left')\njoined.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:17.051066Z","iopub.execute_input":"2021-10-18T09:16:17.051409Z","iopub.status.idle":"2021-10-18T09:16:17.19048Z","shell.execute_reply.started":"2021-10-18T09:16:17.051348Z","shell.execute_reply":"2021-10-18T09:16:17.189346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сбрасываю ненужные столбцы\ndata = joined.drop(['URL_TA','ID_TA'],axis=1)\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:21.26599Z","iopub.execute_input":"2021-10-18T09:16:21.266293Z","iopub.status.idle":"2021-10-18T09:16:21.316411Z","shell.execute_reply.started":"2021-10-18T09:16:21.266246Z","shell.execute_reply":"2021-10-18T09:16:21.315253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Удаление пробелов из названий столбцов\ndef clean_spaces(df):\n    bad_names = []\n    substs = {}\n    for col in list(df.columns):\n        if ' ' in col:\n            bad_names.append(col)\n    for col in bad_names:\n        substs[col] = '_'.join(col.split())\n    # substs\n    df.rename(columns=substs, inplace=True)\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:28.645109Z","iopub.execute_input":"2021-10-18T09:16:28.645573Z","iopub.status.idle":"2021-10-18T09:16:28.652714Z","shell.execute_reply.started":"2021-10-18T09:16:28.645532Z","shell.execute_reply":"2021-10-18T09:16:28.651659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вспомогательная функция для разбора текстового списка видов кухонь\ndef str2list(s):\n    return [ l.strip().strip(\"'\") for l in s.strip('][').split(',') ]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:31.858116Z","iopub.execute_input":"2021-10-18T09:16:31.858421Z","iopub.status.idle":"2021-10-18T09:16:31.863598Z","shell.execute_reply.started":"2021-10-18T09:16:31.858365Z","shell.execute_reply":"2021-10-18T09:16:31.862919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вспомогательные функции для первого разбора столбца отзывов - \n# превращение его в список для дальнейшей обработки.\ndef strip(text):\n    return text[1:-1]\n#\ndef firstsplit(text):\n    text = strip(text)\n    # print(text)\n    if '],' in text:\n        pos = text.rfind('],')\n        return strip(text[:pos+1]), strip(text[pos+3:])\n    else:\n        return '', ''\n#\ndef nextsplit(text):\n    if '\", ' in text:\n        pos = text.find('\", ')\n    elif \"', \" in text:\n        pos = text.find(\"', \")\n    else:\n        return strip(text), ''\n    return strip(text[:pos+1]), strip(text[pos+3:])\n#\ndef split_review(text):\n    # print(text)\n    t,d = firstsplit(text)\n    t1, t2 = nextsplit(t); d1, d2 = nextsplit(d)\n    nr = 2 if len(t1) > 0 and len(t2) > 0 else ( 1 if len(t1) > 0 else 0 )\n    return [nr, t1, t2, d1, d2]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:32:01.719426Z","iopub.execute_input":"2021-10-18T09:32:01.719843Z","iopub.status.idle":"2021-10-18T09:32:01.732165Z","shell.execute_reply.started":"2021-10-18T09:32:01.719773Z","shell.execute_reply":"2021-10-18T09:32:01.730991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Анализ текста с целью выясвления отношения и субьективности написавшего.\n# Использую усредненные значения по двум отзывам, либо единственное значение по одному, либо все по нулям.\n# Еще считается характеристика разброса значений отношения и субьективности - если отзывов два.\ndef analyse_texts(RevList):\n    # RevList[0] - количество опубликованных отзывов\n    # RevList[1] - текст отзыва 1\n    # RevList[2] - текст отзыва 2\n    if RevList[0] == 2:\n        tb1 = TextBlob(RevList[1])\n        # TextBlob - simples method for sentiment analysis\n        p1 = tb1.sentiment.polarity\n        s1 = tb1.sentiment.subjectivity\n        # The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity).\n        # The polarity score is a float within the range [-1.0, 1.0].\n        # The subjectivity is a float within the range [0.0, 1.0]\n        # where 0.0 is very objective and 1.0 is very subjective.\n        # print(RevList[1],p1,s1)\n        tb2 = TextBlob(RevList[2])\n        p2 = tb2.sentiment.polarity\n        s2 = tb2.sentiment.subjectivity\n        # print(RevList[2],p2,s2)\n        p = (p1+p2)/2      #средняя полярность отзывов\n        dp = abs(p2-p1)/2  #разброс полярностей отзывов\n        s = (s1+s2)/2      #средняя субьективность отзывов\n        ds = abs(s2-s1)/2  #разброс субьективностей отзывов\n        return [p, dp, s, ds]\n    elif RevList[0] == 1:\n        tb1 = TextBlob(RevList[1])\n        return [tb1.sentiment.polarity, 0.0, tb1.sentiment.subjectivity, 0.0]\n    else:\n        return[0.0, 0.0, 0.0, 0.0]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:36.925671Z","iopub.execute_input":"2021-10-18T09:16:36.92612Z","iopub.status.idle":"2021-10-18T09:16:36.935381Z","shell.execute_reply.started":"2021-10-18T09:16:36.926079Z","shell.execute_reply":"2021-10-18T09:16:36.934651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Анализ половинки столбца отзывов в виде дат\n# Возвращаем самую свежую дату и разброс дат\ndef analyse_review_dates(RevList):\n    # RevList[0] - количество опубликованных отзывов\n    # RevList[3] - дата отзыва 1\n    # RevList[4] - дата отзыва 2\n    if RevList[3] == '':\n        c1 = 0\n    else:\n        c1 = datetime.strptime(RevList[3],\"%m/%d/%Y\").date().toordinal()\n    if RevList[4] == '':\n        c2 = 0\n    else:\n        c2 = datetime.strptime(RevList[4],\"%m/%d/%Y\").date().toordinal()\n    return [ (c2 if c2>c1 else c1), (abs(c2-c1) if c2>0 else 0) ]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:16:37.882285Z","iopub.execute_input":"2021-10-18T09:16:37.882752Z","iopub.status.idle":"2021-10-18T09:16:37.88972Z","shell.execute_reply.started":"2021-10-18T09:16:37.882709Z","shell.execute_reply":"2021-10-18T09:16:37.889011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df = clean_spaces(df_input.copy())\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df.drop(['Restaurant_id'], axis = 1, inplace=True)\n    \n    \n    # ################### 2. NAN ############################################################## \n    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n    # df['Number of Reviews'].fillna(0, inplace=True)\n    # тут ваш код по обработке NAN\n    # ....\n    csfv = df['Cuisine_Style'].value_counts().idxmax()\n    df['Cuisine_Style'].fillna(csfv, inplace=True)\n    prfv = df['Price_Range'].value_counts().idxmax()\n    df['Price_Range'].fillna(prfv, inplace=True)\n    nrfv = df['Number_of_Reviews'].median()\n    df['Number_of_Reviews'].fillna(nrfv,inplace=True)\n    df['Reviews'].fillna('[[], []]',inplace=True)\n\n    \n    # ################### 3. Encoding ############################################################## \n    # для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n    # df = pd.get_dummies(df, columns=[ 'City',], dummy_na=True)\n    # тут ваш код не Encoding фитчей\n    # ....\n    city_columns = pd.get_dummies(df['City'])\n    df = df.join(city_columns).drop('City',axis=1)\n    country_columns = pd.get_dummies(df['Country_Code'])\n    df = df.join(country_columns).drop('Country_Code',axis=1)\n    df['Log_Population']=np.log10(df.Population)\n    df = df.drop(['Population'],axis=1)\n    \n    # Словарик и преобразование диапазона цен в набор значений\n    # Проверка показала что это более эффективное решение, чем one_hot кодирование. Быстрее и ошибки меньше.\n    PriceRanges = { '$':1.0, '$$$$': 3.0, '$$ - $$$': 2.0 }\n    df['PRange']= df['Price_Range'].apply(lambda c: PriceRanges[c])\n    df = df.drop(['Price_Range'],axis=1)\n\n    # Превращаю поле Cuisine_Style в набор индексов и одну количественную переменную\n    # Вспомогательный столбец со списком кухонь\n    df['CStyles'] = df['Cuisine_Style'].apply(str2list)\n    # СStyles - вспомогательный датафрейм для использования explode\n    # В одной ячейке может содержаться несколько названий кухонь,  поэтому сначала делаю их список через explode\n    # а потом добавляю столбцы с названиями и превращаю их в индексы\n    CStyles = df['Cuisine_Style'].unique()\n    CStyles = pd.Series(CStyles)\n    CStyles = CStyles.apply(str2list)\n    CStyles = CStyles.explode()\n    # CNames - список кухонь\n    CNames = CStyles.unique()\n    for st in CNames:\n        df[st] = df['CStyles'].apply(lambda x: 1 if st in x else 0)\n    df['Num_Cuisines'] = df['CStyles'].apply(len) # это уже дамми переменная с количеством разных кухонь\n    df = df.drop(['CStyles', 'Cuisine_Style'], axis=1)\n    df = clean_spaces(df) # в названиях кухонь встречаются пробелы\n    \n    \n    # ################### 4. Feature Engineering ####################################################\n    # тут ваш код не генерацию новых фитчей\n    # ....\n    # Разбор колонки отзывов в два столбца со списком значений отзывов и\n    # с количеством отзывов для будущего использоваиния\n    df.head(5)\n    df['RL'] = df['Reviews'].apply(split_review)\n    df['Num_Disp_Rev'] = df['RL'].apply(lambda x: x[0])\n    # Разбор текстовой половины отзывов\n    df['TAL'] = df['RL'].apply(analyse_texts)\n    df['Review_polarity'] = df['TAL'].apply(lambda x: x[0])\n    df['Review_polarity_variation'] = df['TAL'].apply(lambda x: x[1])\n    df['Review_subjectivity'] = df['TAL'].apply(lambda x: x[2])\n    df['Review_subjectivity_variation'] = df['TAL'].apply(lambda x: x[3])\n    df = df.drop(['TAL'], axis=1)\n    # Разбор даты отзывов\n    df['RDAL'] = df['RL'].apply(analyse_review_dates)\n    df['Recent_Review_date'] = df['RDAL'].apply(lambda x: x[0])\n    df['Review_dates_span'] = df['RDAL'].apply(lambda x: x[1])\n    df = df.drop(['RDAL'],axis=1)\n    #Удивительным образом заполнение пропусков даты обзора медианой а не нулем дает чуть лучшее значение.\n    # А вот нормализация значений заметным образом не сказывается на итоге.\n    Med_Rec_Rev_Date = df.loc[df.Recent_Review_date>0,'Recent_Review_date'].median()\n    df['Recent_Review_date'] = df['Recent_Review_date'].apply(lambda x: x if x > 0 else Med_Rec_Rev_Date)\n    \n    \n    # ################### 5. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df.columns if df[s].dtypes == 'object']\n    df.drop(object_columns, axis = 1, inplace=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:33:19.653304Z","iopub.execute_input":"2021-10-18T09:33:19.653697Z","iopub.status.idle":"2021-10-18T09:33:19.682307Z","shell.execute_reply.started":"2021-10-18T09:33:19.653632Z","shell.execute_reply":"2021-10-18T09:33:19.681489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось","metadata":{}},{"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:33:21.603811Z","iopub.execute_input":"2021-10-18T09:33:21.604382Z","iopub.status.idle":"2021-10-18T09:34:11.09265Z","shell.execute_reply.started":"2021-10-18T09:33:21.604335Z","shell.execute_reply":"2021-10-18T09:34:11.091165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preproc.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:35:09.14924Z","iopub.execute_input":"2021-10-18T09:35:09.149686Z","iopub.status.idle":"2021-10-18T09:35:09.182096Z","shell.execute_reply.started":"2021-10-18T09:35:09.149628Z","shell.execute_reply":"2021-10-18T09:35:09.181112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:35:25.37184Z","iopub.execute_input":"2021-10-18T09:35:25.372229Z","iopub.status.idle":"2021-10-18T09:35:25.635143Z","shell.execute_reply.started":"2021-10-18T09:35:25.372163Z","shell.execute_reply":"2021-10-18T09:35:25.633853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**","metadata":{}},{"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:35:38.364148Z","iopub.execute_input":"2021-10-18T09:35:38.364552Z","iopub.status.idle":"2021-10-18T09:35:38.439968Z","shell.execute_reply.started":"2021-10-18T09:35:38.364471Z","shell.execute_reply":"2021-10-18T09:35:38.439019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:35:44.137825Z","iopub.execute_input":"2021-10-18T09:35:44.138144Z","iopub.status.idle":"2021-10-18T09:35:44.145412Z","shell.execute_reply.started":"2021-10-18T09:35:44.138098Z","shell.execute_reply":"2021-10-18T09:35:44.144366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model \nСам ML","metadata":{}},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:36:04.284429Z","iopub.execute_input":"2021-10-18T09:36:04.284915Z","iopub.status.idle":"2021-10-18T09:36:04.406227Z","shell.execute_reply.started":"2021-10-18T09:36:04.284872Z","shell.execute_reply":"2021-10-18T09:36:04.405311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:36:05.023443Z","iopub.execute_input":"2021-10-18T09:36:05.023794Z","iopub.status.idle":"2021-10-18T09:36:05.028421Z","shell.execute_reply.started":"2021-10-18T09:36:05.023743Z","shell.execute_reply":"2021-10-18T09:36:05.027753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)\ny_pred2 = (y_pred*2).round()/2","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:28.671565Z","iopub.execute_input":"2021-10-18T09:56:28.672047Z","iopub.status.idle":"2021-10-18T09:56:48.535867Z","shell.execute_reply.started":"2021-10-18T09:56:28.671964Z","shell.execute_reply":"2021-10-18T09:56:48.534765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE: ', metrics.mean_absolute_error(y_test, y_pred))\nprint('MAE2:', metrics.mean_absolute_error(y_test, y_pred2))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:48.537676Z","iopub.execute_input":"2021-10-18T09:56:48.53793Z","iopub.status.idle":"2021-10-18T09:56:48.546041Z","shell.execute_reply.started":"2021-10-18T09:56:48.537894Z","shell.execute_reply":"2021-10-18T09:56:48.545022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл","metadata":{}},{"cell_type":"code","source":"test_data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:17:56.385753Z","iopub.execute_input":"2021-10-18T10:17:56.386138Z","iopub.status.idle":"2021-10-18T10:17:56.442557Z","shell.execute_reply.started":"2021-10-18T10:17:56.386074Z","shell.execute_reply":"2021-10-18T10:17:56.441487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:18:01.798091Z","iopub.execute_input":"2021-10-18T10:18:01.798567Z","iopub.status.idle":"2021-10-18T10:18:01.832841Z","shell.execute_reply.started":"2021-10-18T10:18:01.798523Z","shell.execute_reply":"2021-10-18T10:18:01.831721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:18:03.90271Z","iopub.execute_input":"2021-10-18T10:18:03.903024Z","iopub.status.idle":"2021-10-18T10:18:03.915944Z","shell.execute_reply.started":"2021-10-18T10:18:03.902977Z","shell.execute_reply":"2021-10-18T10:18:03.915289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_submission = model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:18:13.717425Z","iopub.execute_input":"2021-10-18T10:18:13.718018Z","iopub.status.idle":"2021-10-18T10:18:13.940273Z","shell.execute_reply.started":"2021-10-18T10:18:13.717949Z","shell.execute_reply":"2021-10-18T10:18:13.939192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_submission = (predict_submission*2).round()/2\npredict_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:18:36.159354Z","iopub.execute_input":"2021-10-18T10:18:36.159667Z","iopub.status.idle":"2021-10-18T10:18:36.16817Z","shell.execute_reply.started":"2021-10-18T10:18:36.159627Z","shell.execute_reply":"2021-10-18T10:18:36.167379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T10:18:45.069127Z","iopub.execute_input":"2021-10-18T10:18:45.069669Z","iopub.status.idle":"2021-10-18T10:18:45.686072Z","shell.execute_reply.started":"2021-10-18T10:18:45.069606Z","shell.execute_reply":"2021-10-18T10:18:45.685379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What's next?\nИли что делать, чтоб улучшить результат:\n* Обработать оставшиеся признаки в понятный для машины формат\n* Посмотреть, что еще можно извлечь из признаков\n* Сгенерировать новые признаки\n* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n* Подобрать состав признаков\n\nВ общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}